{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Universidad del Valle de Guatemala\n",
    "#### Brandon Ronaldo Sicay Cumes - 21757\n",
    "##### Modelo base, métricas personalizadas, función optimización\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Proyecto Final: Detectar patrones secuenciales de fraude**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descripción del problema: Optimizar el modelo para detectar fraudes que ocurren en secuencia o con patrones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo Base\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting lightgbm\n",
      "  Downloading lightgbm-4.6.0-py3-none-macosx_12_0_arm64.whl (1.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.6 MB 1.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy in /Users/brand/Library/Python/3.9/lib/python/site-packages (from lightgbm) (1.11.4)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /Users/brand/Library/Python/3.9/lib/python/site-packages (from lightgbm) (1.26.4)\n",
      "Installing collected packages: lightgbm\n",
      "Successfully installed lightgbm-4.6.0\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.1.1 is available.\n",
      "You should consider upgrading via the '/Applications/Xcode.app/Contents/Developer/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install lightgbm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, f1_score, confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparación y Separación de Datos\n",
    "\n",
    "## 1. Carga de Datos\n",
    "\n",
    "Importamos el dataset preprocesado con las nuevas variables creadas.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cy/x57dh4ds2g123w7nj93wcf_c0000gn/T/ipykernel_61930/3659505003.py:2: DtypeWarning: Columns (39,42,48,64) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('./docs/Caracteristicas_final.csv')\n"
     ]
    }
   ],
   "source": [
    "# Cargar el dataset final con nuevas features\n",
    "df = pd.read_csv('./docs/Caracteristicas_final.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 2. Separación de la Data\n",
    "\n",
    "Dividimos los datos de entrenamiento y prueba siguiendo una separación temporal, utilizando como testing el último trimestre (octubre a diciembre) de 2020.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos un filtro para test: último trimestre de 2020\n",
    "test_mask = (df['trans_month'].isin([10, 11, 12])) & (df['year'] == 2020)\n",
    "\n",
    "# División en train y test\n",
    "df_train = df[~test_mask]\n",
    "df_test = df[test_mask]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 3. Definición de Variables Dependientes e Independientes\n",
    "Separamos las variables predictoras (features) y la variable objetivo (is_sequential_fraud_pattern).\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir X e y\n",
    "X_train = df_train.drop(columns=['is_sequential_fraud_pattern'])\n",
    "y_train = df_train['is_sequential_fraud_pattern']\n",
    "\n",
    "X_test = df_test.drop(columns=['is_sequential_fraud_pattern'])\n",
    "y_test = df_test['is_sequential_fraud_pattern']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 4. Identificación de Variables Categóricas y Numéricas\n",
    "Identificamos las variables categóricas y numéricas del dataset.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables categóricas: ['timestamp', 'merchant', 'category', 'first', 'last', 'gender', 'street', 'city', 'state', 'job', 'dob', 'trans_num', 'unix_time', 'secs_since_last_trans', 'fraud_secs_gap_x', 'min_fraud_gap_secs_x', 'mean_fraud_gap_secs_x', 'fraud_secs_gap_y', 'min_fraud_gap_secs_y', 'mean_fraud_gap_secs_y', 'last_fraud_time', 'days_since_last_fraud', 'fraud_secs_gap', 'min_fraud_gap_secs', 'mean_fraud_gap_secs', 'date', 'time_since_last_event', 'fraud_to_fraud_time', 'fraud_legit_gap']\n",
      "Variables numéricas: ['cc_num', 'amt', 'zip', 'lat', 'long', 'city_pop', 'merch_lat', 'merch_long', 'is_fraud', 'amt_month', 'amt_year', 'amt_month_shopping_net_spend', 'count_month_shopping_net', 'dist_between_client_and_merch', 'trans_month', 'trans_day', 'hour', 'year', 'times_shopped_at_merchant', 'times_shopped_at_merchant_year', 'times_shopped_at_merchant_month', 'times_shopped_at_merchant_day', 'trans_rolling_1h', 'rolling_amt_mean_1h', 'trans_dist_km', 'daily_amt_std', 'mean_amt', 'std_amt', 'amt_high_flag', 'unique_merchants_day', 'same_merchant_seq_count', 'new_merchant_flag', 'merchant_repeats_day', 'consec_fraud_flag', 'consecutive_frauds', 'fraud_cluster_size', 'fraud_legit_gap_ratio']\n"
     ]
    }
   ],
   "source": [
    "# Columnas categóricas y numéricas\n",
    "categorical_cols = X_train.select_dtypes(include=['object', 'category']).columns\n",
    "numerical_cols = X_train.select_dtypes(include='number').columns\n",
    "\n",
    "print(\"Variables categóricas:\", list(categorical_cols))\n",
    "print(\"Variables numéricas:\", list(numerical_cols))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 5. Procesamiento de Variables Categóricas\n",
    "Codificamos las variables categóricas usando Label Encoding para que LightGBM pueda procesarlas adecuadamente. Además, manejamos valores < unknown > en el conjunto de prueba para valores no vistos durante el entrenamiento.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluación de modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import bisect\n",
    "import numpy as np\n",
    "\n",
    "# Copiar datasets\n",
    "X_train_processed = X_train.copy()\n",
    "X_test_processed = X_test.copy()\n",
    "\n",
    "# Procesar variables categóricas\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    X_train_processed[col] = le.fit_transform(X_train[col].astype(str))\n",
    "    \n",
    "    # Mapeo especial para valores no vistos\n",
    "    X_test_processed[col] = X_test[col].astype(str).map(lambda s: '<unknown>' if s not in le.classes_ else s)\n",
    "\n",
    "    if '<unknown>' not in le.classes_:\n",
    "        if X_test_processed[col].eq('<unknown>').any():\n",
    "            le_classes = le.clases_.tolist()\n",
    "            bisect.insort_left(le_classes, '<unknown>')\n",
    "            le.classes_ = np.array(le_classes)\n",
    "    \n",
    "    X_test_processed[col] = le.transform(X_test_processed[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento del Modelo Base\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "params = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'auc',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'learning_rate': 0.05,\n",
    "    'num_leaves': 31,\n",
    "    'max_depth': -1,\n",
    "    'is_unbalance': True,\n",
    "    'n_jobs': 4,\n",
    "    'seed': 42\n",
    "}\n",
    "\n",
    "train_data = lgb.Dataset(X_train, label=y_train)\n",
    "test_data = lgb.Dataset(X_test, label=y_test, reference=train_data)\n",
    "\n",
    "# Entrenar modelo inicial\n",
    "model_base = lgb.train(\n",
    "    params,\n",
    "    train_data,\n",
    "    num_boost_round=1000,\n",
    "    valid_sets=[test_data],\n",
    "    early_stopping_rounds=50,\n",
    "    verbose_eval=100\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
